#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì›¹ ê¸°ë°˜ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬
ERPia ìë™ ë°ì´í„° ìˆ˜ì§‘ì„ ì›¹ì—ì„œ ì„¤ì •í•˜ê³  ê´€ë¦¬
"""

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from apscheduler.executors.pool import ThreadPoolExecutor
from apscheduler.events import EVENT_JOB_EXECUTED, EVENT_JOB_ERROR
import logging
import traceback
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import pytz
import json
from flask import current_app

from .erpia_client import ErpiaApiClient
from .gift_classifier import GiftClassifier

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

@dataclass
class BatchJobConfig:
    """ë°°ì¹˜ ì‘ì—… ì„¤ì •"""
    job_id: str
    name: str
    job_type: str  # DAILY_COLLECTION, CUSTOMER_SYNC, GIFT_CLASSIFY, REPORT_GENERATE
    company_id: int
    enabled: bool = True
    schedule_type: str = "cron"  # cron, interval
    cron_expression: str = "0 2 * * *"  # ë§¤ì¼ ì˜¤ì „ 2ì‹œ
    interval_minutes: int = 60
    max_instances: int = 1
    coalesce: bool = True
    misfire_grace_time: int = 300  # 5ë¶„
    timezone: str = "Asia/Seoul"
    parameters: Dict[str, Any] = None
    created_at: datetime = None
    updated_at: datetime = None

    def __post_init__(self):
        if self.parameters is None:
            self.parameters = {}
        if self.created_at is None:
            self.created_at = datetime.now()

@dataclass 
class BatchExecutionResult:
    """ë°°ì¹˜ ì‹¤í–‰ ê²°ê³¼"""
    job_id: str
    execution_id: str
    started_at: datetime
    finished_at: datetime = None
    status: str = "RUNNING"  # RUNNING, SUCCESS, FAILED
    message: str = ""
    details: Dict[str, Any] = None
    error_trace: str = ""
    processed_count: int = 0
    company_id: int = 1

class BatchScheduler:
    """ì›¹ ê¸°ë°˜ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self, app=None):
        """
        Args:
            app: Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤
        """
        self.app = app
        self.scheduler = None
        self.erpia_clients = {}  # íšŒì‚¬ë³„ ERPia í´ë¼ì´ì–¸íŠ¸ ìºì‹œ
        self.gift_classifier = None
        self.is_running = False
        
        if app:
            self.init_app(app)
    
    def init_app(self, app):
        """Flask ì•±ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”"""
        try:
            self.app = app
            self.app.scheduler = self
            
            # APScheduler BackgroundScheduler ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë©”ëª¨ë¦¬ ê¸°ë°˜ jobstore ì‚¬ìš© (ì•ˆì •ì„±)
            if app.config.get('ENV') == 'development':
                jobstores = {
                    'default': 'memory'
                }
            else:
                jobstores = {
                    'default': SQLAlchemyJobStore(url=app.config.get('SQLALCHEMY_DATABASE_URI'))
                }
                
            executors = {
                'default': ThreadPoolExecutor(20),
            }
            job_defaults = {
                'coalesce': False,
                'max_instances': 3
            }
            
            self.scheduler = BackgroundScheduler(
                jobstores=jobstores,
                executors=executors,
                job_defaults=job_defaults,
                timezone=pytz.timezone('Asia/Seoul')
            )
            
            # ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
            self.scheduler.add_listener(self._job_executed_listener, EVENT_JOB_EXECUTED)
            self.scheduler.add_listener(self._job_error_listener, EVENT_JOB_ERROR)
            
            # ë°°ì¹˜ ì‘ì—…ìš© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (íšŒì‚¬ë³„ ë™ì  ìƒì„±ìœ¼ë¡œ ë³€ê²½)
            # self.gift_classifier = GiftClassifier()  # íšŒì‚¬ë³„ë¡œ ë™ì  ìƒì„±
            
            print("ğŸ”§ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ìˆ˜ë™ ì‹œì‘
            if app.config.get('ENV') == 'development':
                print("ğŸ’¡ ê°œë°œ í™˜ê²½: ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ìˆ˜ë™ ì‹œì‘ ëª¨ë“œ")
                print("   - /batch í˜ì´ì§€ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                self.start()
                
        except Exception as e:
            print(f"âš ï¸ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            # ì´ˆê¸°í™” ì‹¤íŒ¨í•´ë„ ì•±ì€ ê³„ì† ì‹¤í–‰
    
    def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if not self.is_running:
            try:
                self.scheduler.start()
                self.is_running = True
                logger.info("ğŸš€ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨")
                
                # ê¸°ë³¸ ì‘ì—…ë“¤ ë“±ë¡
                self._register_default_jobs()
                
            except Exception as e:
                logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")
                raise
    
    def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        if self.is_running and self.scheduler:
            try:
                self.scheduler.shutdown(wait=False)
                self.is_running = False
                logger.info("â¹ï¸ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ë¨")
            except Exception as e:
                logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ ì‹¤íŒ¨: {e}")
    
    def add_job(self, job_config: BatchJobConfig) -> bool:
        """ë°°ì¹˜ ì‘ì—… ì¶”ê°€"""
        try:
            if not self.is_running:
                logger.warning("âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.")
                return False
            
            # ê¸°ì¡´ ì‘ì—… ì œê±° (ìˆëŠ” ê²½ìš°)
            try:
                self.scheduler.remove_job(job_config.job_id)
            except:
                pass
            
            # ì‘ì—… í•¨ìˆ˜ ë§¤í•‘
            job_func = self._get_job_function(job_config.job_type)
            if not job_func:
                logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—… íƒ€ì…: {job_config.job_type}")
                return False
            
            # ìŠ¤ì¼€ì¤„ ì„¤ì •
            if job_config.schedule_type == "cron":
                # Cron í‘œí˜„ì‹ íŒŒì‹± (ë¶„ ì‹œ ì¼ ì›” ìš”ì¼)
                cron_parts = job_config.cron_expression.split()
                if len(cron_parts) != 5:
                    logger.error(f"âŒ ì˜ëª»ëœ Cron í‘œí˜„ì‹: {job_config.cron_expression}")
                    return False
                
                minute, hour, day, month, day_of_week = cron_parts
                
                self.scheduler.add_job(
                    job_func,
                    'cron',
                    id=job_config.job_id,
                    name=job_config.name,
                    minute=minute,
                    hour=hour,
                    day=day,
                    month=month,
                    day_of_week=day_of_week,
                    max_instances=job_config.max_instances,
                    coalesce=job_config.coalesce,
                    misfire_grace_time=job_config.misfire_grace_time,
                    timezone=job_config.timezone,
                    args=[job_config]
                )
            else:
                # ì¸í„°ë²Œ ìŠ¤ì¼€ì¤„
                self.scheduler.add_job(
                    job_func,
                    'interval',
                    id=job_config.job_id,
                    name=job_config.name,
                    minutes=job_config.interval_minutes,
                    max_instances=job_config.max_instances,
                    coalesce=job_config.coalesce,
                    misfire_grace_time=job_config.misfire_grace_time,
                    timezone=job_config.timezone,
                    args=[job_config]
                )
            
            # DBì— ì‘ì—… ì„¤ì • ì €ì¥
            self._save_job_config(job_config)
            
            logger.info(f"âœ… ë°°ì¹˜ ì‘ì—… ì¶”ê°€ë¨: {job_config.name} ({job_config.job_id})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì‘ì—… ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def remove_job(self, job_id: str) -> bool:
        """ë°°ì¹˜ ì‘ì—… ì œê±°"""
        try:
            self.scheduler.remove_job(job_id)
            
            # DBì—ì„œ ì„¤ì • ì‚­ì œ
            self._delete_job_config(job_id)
            
            logger.info(f"âœ… ë°°ì¹˜ ì‘ì—… ì œê±°ë¨: {job_id}")
            return True
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ì‘ì—… ì œê±° ì‹¤íŒ¨ ({job_id}): {e}")
            return False
    
    def get_jobs(self) -> List[Dict[str, Any]]:
        """ë“±ë¡ëœ ë°°ì¹˜ ì‘ì—… ëª©ë¡ ì¡°íšŒ"""
        try:
            jobs = []
            for job in self.scheduler.get_jobs():
                job_info = {
                    'id': job.id,
                    'name': job.name,
                    'next_run_time': job.next_run_time.isoformat() if job.next_run_time else None,
                    'trigger': str(job.trigger),
                    'func_name': job.func.__name__ if job.func else '',
                    'args': len(job.args) if job.args else 0,
                    'kwargs': len(job.kwargs) if job.kwargs else 0
                }
                jobs.append(job_info)
            return jobs
        except Exception as e:
            logger.error(f"âŒ ì‘ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def run_job_now(self, job_id: str) -> bool:
        """ë°°ì¹˜ ì‘ì—… ì¦‰ì‹œ ì‹¤í–‰"""
        try:
            job = self.scheduler.get_job(job_id)
            if not job:
                logger.error(f"âŒ ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {job_id}")
                return False
            
            # ì¦‰ì‹œ ì‹¤í–‰
            job.func(*job.args, **job.kwargs)
            logger.info(f"ğŸš€ ì‘ì—… ì¦‰ì‹œ ì‹¤í–‰ë¨: {job_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì‘ì—… ì¦‰ì‹œ ì‹¤í–‰ ì‹¤íŒ¨ ({job_id}): {e}")
            return False
    
    def _get_job_function(self, job_type: str):
        """ì‘ì—… íƒ€ì…ì— ë”°ë¥¸ í•¨ìˆ˜ ë°˜í™˜"""
        job_functions = {
            'DAILY_COLLECTION': self._daily_collection_job,
            'CUSTOMER_SYNC': self._customer_sync_job,
            'GIFT_CLASSIFY': self._gift_classify_job,
            'REPORT_GENERATE': self._report_generate_job,
            'DATA_CLEANUP': self._data_cleanup_job
        }
        return job_functions.get(job_type)
    
    def _daily_collection_job(self, job_config: BatchJobConfig):
        """ì¼ì¼ ERPia ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…"""
        execution_id = f"{job_config.job_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        result = BatchExecutionResult(
            job_id=job_config.job_id,
            execution_id=execution_id,
            started_at=datetime.now(),
            company_id=job_config.company_id
        )
        
        try:
            logger.info(f"ğŸ”„ ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {job_config.name}")
            
            # ERPia í´ë¼ì´ì–¸íŠ¸ íšë“
            erpia_client = self._get_erpia_client(job_config.company_id)
            
            # ìˆ˜ì§‘í•  ë‚ ì§œ ê²°ì • (ì–´ì œ ë‚ ì§œ)
            target_date = job_config.parameters.get('target_date')
            if not target_date:
                yesterday = datetime.now() - timedelta(days=1)
                target_date = yesterday.strftime('%Y%m%d')
            
            # ì£¼ë¬¸ ë°ì´í„° ìˆ˜ì§‘
            order_data = erpia_client.get_daily_orders(target_date)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            saved_count = self._save_order_data(order_data)
            
            # ìë™ ì‚¬ì€í’ˆ ë¶„ë¥˜ (ì„¤ì •ëœ ê²½ìš°)
            if job_config.parameters.get('auto_gift_classify', True):
                self.gift_classifier.classify_orders(order_data['orders'])
            
            # ì‹¤í–‰ ê²°ê³¼ ì €ì¥
            result.status = "SUCCESS"
            result.message = f"ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {saved_count}ê±´"
            result.processed_count = saved_count
            result.details = {
                'target_date': target_date,
                'orders_count': order_data['total_orders'],
                'products_count': order_data['total_products'],
                'deliveries_count': order_data['total_deliveries']
            }
            
            logger.info(f"âœ… ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {saved_count}ê±´")
            
        except Exception as e:
            error_trace = traceback.format_exc()
            result.status = "FAILED"
            result.message = f"ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
            result.error_trace = error_trace
            logger.error(f"âŒ ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            
        finally:
            result.finished_at = datetime.now()
            self._save_execution_result(result)
    
    def _customer_sync_job(self, job_config: BatchJobConfig):
        """ê³ ê° ì •ë³´ ë™ê¸°í™” ì‘ì—…"""
        execution_id = f"{job_config.job_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        result = BatchExecutionResult(
            job_id=job_config.job_id,
            execution_id=execution_id,
            started_at=datetime.now(),
            company_id=job_config.company_id
        )
        
        try:
            logger.info(f"ğŸ”„ ê³ ê° ì •ë³´ ë™ê¸°í™” ì‹œì‘: {job_config.name}")
            
            erpia_client = self._get_erpia_client(job_config.company_id)
            
            # ë™ê¸°í™” ê¸°ê°„ ì„¤ì • (ê¸°ë³¸: ìµœê·¼ 30ì¼)
            days_back = job_config.parameters.get('days_back', 30)
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days_back)
            
            start_date_str = start_date.strftime('%Y%m%d')
            end_date_str = end_date.strftime('%Y%m%d')
            
            # ê³ ê° ë°ì´í„° ìˆ˜ì§‘
            customers = erpia_client.get_customer_list(start_date_str, end_date_str)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥/ì—…ë°ì´íŠ¸
            saved_count = self._save_customer_data(customers)
            
            result.status = "SUCCESS"
            result.message = f"ê³ ê° ë™ê¸°í™” ì™„ë£Œ: {saved_count}ê±´"
            result.processed_count = saved_count
            result.details = {
                'period': f"{start_date_str} ~ {end_date_str}",
                'customers_count': len(customers)
            }
            
            logger.info(f"âœ… ê³ ê° ì •ë³´ ë™ê¸°í™” ì™„ë£Œ: {saved_count}ê±´")
            
        except Exception as e:
            error_trace = traceback.format_exc()
            result.status = "FAILED"
            result.message = f"ë™ê¸°í™” ì‹¤íŒ¨: {str(e)}"
            result.error_trace = error_trace
            logger.error(f"âŒ ê³ ê° ì •ë³´ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            
        finally:
            result.finished_at = datetime.now()
            self._save_execution_result(result)
    
    def _gift_classify_job(self, job_config: BatchJobConfig):
        """ì‚¬ì€í’ˆ ìë™ ë¶„ë¥˜ ì‘ì—…"""
        execution_id = f"{job_config.job_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        result = BatchExecutionResult(
            job_id=job_config.job_id,
            execution_id=execution_id,
            started_at=datetime.now(),
            company_id=job_config.company_id
        )
        
        try:
            logger.info(f"ğŸ”„ ì‚¬ì€í’ˆ ìë™ ë¶„ë¥˜ ì‹œì‘: {job_config.name}")
            
            # ë¶„ë¥˜í•  ê¸°ê°„ ì„¤ì •
            days_back = job_config.parameters.get('days_back', 7)
            
            # ë¯¸ë¶„ë¥˜ ìƒí’ˆ ë¶„ë¥˜
            classified_count = self.gift_classifier.auto_classify_recent_products(
                company_id=job_config.company_id,
                days_back=days_back
            )
            
            result.status = "SUCCESS"
            result.message = f"ì‚¬ì€í’ˆ ë¶„ë¥˜ ì™„ë£Œ: {classified_count}ê±´"
            result.processed_count = classified_count
            result.details = {
                'days_back': days_back,
                'classified_count': classified_count
            }
            
            logger.info(f"âœ… ì‚¬ì€í’ˆ ìë™ ë¶„ë¥˜ ì™„ë£Œ: {classified_count}ê±´")
            
        except Exception as e:
            error_trace = traceback.format_exc()
            result.status = "FAILED"
            result.message = f"ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}"
            result.error_trace = error_trace
            logger.error(f"âŒ ì‚¬ì€í’ˆ ìë™ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            
        finally:
            result.finished_at = datetime.now()
            self._save_execution_result(result)
    
    def _report_generate_job(self, job_config: BatchJobConfig):
        """ë³´ê³ ì„œ ìƒì„± ì‘ì—…"""
        execution_id = f"{job_config.job_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        result = BatchExecutionResult(
            job_id=job_config.job_id,
            execution_id=execution_id,
            started_at=datetime.now(),
            company_id=job_config.company_id
        )
        
        try:
            logger.info(f"ğŸ”„ ë³´ê³ ì„œ ìƒì„± ì‹œì‘: {job_config.name}")
            
            # ë³´ê³ ì„œ ìƒì„± ë¡œì§ (ì¶”í›„ êµ¬í˜„)
            # - ì¼ì¼/ì£¼ê°„/ì›”ê°„ ë§¤ì¶œ ë³´ê³ ì„œ
            # - ì‚¬ì€í’ˆ ë¶„ì„ ë³´ê³ ì„œ
            # - ê±°ë˜ì²˜ë³„ ë§¤ì¶œ í˜„í™©
            
            result.status = "SUCCESS"
            result.message = "ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ"
            result.processed_count = 1
            
            logger.info("âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            error_trace = traceback.format_exc()
            result.status = "FAILED"
            result.message = f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}"
            result.error_trace = error_trace
            logger.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            
        finally:
            result.finished_at = datetime.now()
            self._save_execution_result(result)
    
    def _data_cleanup_job(self, job_config: BatchJobConfig):
        """ë°ì´í„° ì •ë¦¬ ì‘ì—…"""
        execution_id = f"{job_config.job_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        result = BatchExecutionResult(
            job_id=job_config.job_id,
            execution_id=execution_id,
            started_at=datetime.now(),
            company_id=job_config.company_id
        )
        
        try:
            logger.info(f"ğŸ”„ ë°ì´í„° ì •ë¦¬ ì‹œì‘: {job_config.name}")
            
            # ì˜¤ë˜ëœ ë¡œê·¸ ë°ì´í„° ì •ë¦¬
            # ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ ë“±
            
            result.status = "SUCCESS"
            result.message = "ë°ì´í„° ì •ë¦¬ ì™„ë£Œ"
            result.processed_count = 0
            
            logger.info("âœ… ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            error_trace = traceback.format_exc()
            result.status = "FAILED"
            result.message = f"ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {str(e)}"
            result.error_trace = error_trace
            logger.error(f"âŒ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
        finally:
            result.finished_at = datetime.now()
            self._save_execution_result(result)
    
    def _get_erpia_client(self, company_id: int) -> ErpiaApiClient:
        """íšŒì‚¬ë³„ ERPia í´ë¼ì´ì–¸íŠ¸ íšë“ (ìºì‹œë¨)"""
        if company_id not in self.erpia_clients:
            self.erpia_clients[company_id] = ErpiaApiClient(company_id)
        return self.erpia_clients[company_id]
    
    def _save_order_data(self, order_data: Dict[str, Any]) -> int:
        """ì£¼ë¬¸ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            from app.common.models import ErpiaOrderMaster, ErpiaOrderProduct, ErpiaOrderDelivery, db
            
            saved_count = 0
            
            with db.session.begin():
                # ì£¼ë¬¸ ë§ˆìŠ¤í„° ì €ì¥
                for order in order_data['orders']:
                    # ì¤‘ë³µ ì²´í¬
                    existing = ErpiaOrderMaster.query.filter_by(
                        sl_no=order.sl_no,
                        company_id=order.company_id
                    ).first()
                    
                    if not existing:
                        master_model = ErpiaOrderMaster(**order.__dict__)
                        db.session.add(master_model)
                        saved_count += 1
                
                # ìƒí’ˆ ì €ì¥
                for product in order_data['products']:
                    existing = ErpiaOrderProduct.query.filter_by(
                        sl_no=product.sl_no,
                        sl_seq=product.sl_seq,
                        company_id=product.company_id
                    ).first()
                    
                    if not existing:
                        product_model = ErpiaOrderProduct(**product.__dict__)
                        db.session.add(product_model)
                
                # ë°°ì†¡ ì •ë³´ ì €ì¥
                for delivery in order_data['deliveries']:
                    existing = ErpiaOrderDelivery.query.filter_by(
                        sl_no=delivery.sl_no,
                        company_id=delivery.company_id
                    ).first()
                    
                    if not existing:
                        delivery_model = ErpiaOrderDelivery(**delivery.__dict__)
                        db.session.add(delivery_model)
            
            return saved_count
            
        except Exception as e:
            logger.error(f"âŒ ì£¼ë¬¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
    
    def _save_customer_data(self, customers: List) -> int:
        """ê³ ê° ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥/ì—…ë°ì´íŠ¸"""
        try:
            from app.common.models import ErpiaCustomer, db
            
            saved_count = 0
            
            with db.session.begin():
                for customer in customers:
                    existing = ErpiaCustomer.query.filter_by(
                        g_code=customer.g_code,
                        company_id=customer.company_id
                    ).first()
                    
                    if existing:
                        # ì—…ë°ì´íŠ¸
                        for key, value in customer.__dict__.items():
                            if hasattr(existing, key):
                                setattr(existing, key, value)
                    else:
                        # ì‹ ê·œ ì¶”ê°€
                        customer_model = ErpiaCustomer(**customer.__dict__)
                        db.session.add(customer_model)
                        saved_count += 1
            
            return saved_count
            
        except Exception as e:
            logger.error(f"âŒ ê³ ê° ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
    
    def _save_job_config(self, job_config: BatchJobConfig):
        """ì‘ì—… ì„¤ì •ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            from app.common.models import BatchJobConfig as JobConfigModel, db
            
            existing = JobConfigModel.query.filter_by(job_id=job_config.job_id).first()
            if existing:
                # ì—…ë°ì´íŠ¸
                for key, value in job_config.__dict__.items():
                    if hasattr(existing, key):
                        setattr(existing, key, value)
                existing.updated_at = datetime.now()
            else:
                # ì‹ ê·œ ì¶”ê°€
                config_model = JobConfigModel(**job_config.__dict__)
                db.session.add(config_model)
            
            db.session.commit()
            
        except Exception as e:
            logger.error(f"âŒ ì‘ì—… ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _delete_job_config(self, job_id: str):
        """ì‘ì—… ì„¤ì •ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚­ì œ"""
        try:
            from app.common.models import BatchJobConfig as JobConfigModel, db
            
            config = JobConfigModel.query.filter_by(job_id=job_id).first()
            if config:
                db.session.delete(config)
                db.session.commit()
                
        except Exception as e:
            logger.error(f"âŒ ì‘ì—… ì„¤ì • ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    def _save_execution_result(self, result: BatchExecutionResult):
        """ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            from app.common.models import BatchExecutionResult as ResultModel, db
            
            result_model = ResultModel(**result.__dict__)
            if result.details:
                result_model.details = json.dumps(result.details, ensure_ascii=False)
            
            db.session.add(result_model)
            db.session.commit()
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤í–‰ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _register_default_jobs(self):
        """ê¸°ë³¸ ë°°ì¹˜ ì‘ì—… ë“±ë¡"""
        try:
            current_app.logger.info("ğŸ”§ ê¸°ë³¸ ë°°ì¹˜ ì‘ì—… ë“±ë¡ ì‹œì‘")
            
            # ê¸°ë³¸ ì‘ì—… ì„¤ì •ë“¤
            default_jobs = [
                {
                    'job_id': 'daily_erpia_sync_aone',
                    'name': 'ì—ì´ì› ERPia ì¼ì¼ ë™ê¸°í™”',
                    'job_type': 'DAILY_COLLECTION',
                    'company_id': 1,
                    'enabled': True,
                    'cron_expression': '0 2 * * *',  # ë§¤ì¼ ì˜¤ì „ 2ì‹œ
                    'parameters': {
                        'api_interval': 3,
                        'page_size': 30,
                        'data_types': ['orders', 'customers', 'products']
                    }
                },
                {
                    'job_id': 'daily_erpia_sync_aone_world',
                    'name': 'ì—ì´ì›ì›”ë“œ ERPia ì¼ì¼ ë™ê¸°í™”',
                    'job_type': 'DAILY_COLLECTION',
                    'company_id': 2,
                    'enabled': True,
                    'cron_expression': '0 3 * * *',  # ë§¤ì¼ ì˜¤ì „ 3ì‹œ
                    'parameters': {
                        'api_interval': 3,
                        'page_size': 30,
                        'data_types': ['orders', 'customers', 'products']
                    }
                },
                {
                    'job_id': 'daily_customer_sync',
                    'name': 'ê³ ê° ì •ë³´ ë™ê¸°í™”',
                    'job_type': 'CUSTOMER_SYNC',
                    'company_id': 1,
                    'enabled': True,
                    'cron_expression': '0 4 * * *',  # ë§¤ì¼ ì˜¤ì „ 4ì‹œ
                    'parameters': {
                        'update_existing': True,
                        'sync_all': False
                    }
                },
                {
                    'job_id': 'daily_gift_classify',
                    'name': 'ì‚¬ì€í’ˆ ìë™ ë¶„ë¥˜',
                    'job_type': 'GIFT_CLASSIFY',
                    'company_id': 1,
                    'enabled': True,
                    'cron_expression': '0 5 * * *',  # ë§¤ì¼ ì˜¤ì „ 5ì‹œ
                    'parameters': {
                        'classify_zero_price': True,
                        'keyword_matching': True,
                        'update_statistics': True
                    }
                }
            ]
            
            # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì—†ì„ ìˆ˜ ìˆìŒ
            if not self.scheduler:
                current_app.logger.warning("âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‘ì—… ë“±ë¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return
            
            # ê¸°ë³¸ ì‘ì—… ë“±ë¡
            for job_data in default_jobs:
                try:
                    job_config = BatchJobConfig(**job_data)
                    
                    # ì´ë¯¸ ë“±ë¡ëœ ì‘ì—…ì¸ì§€ í™•ì¸
                    existing_job = self.scheduler.get_job(job_config.job_id)
                    if existing_job:
                        current_app.logger.info(f"ğŸ“‹ ê¸°ë³¸ ì‘ì—… ì´ë¯¸ ì¡´ì¬: {job_config.name}")
                        continue
                    
                    # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ì‹¤ì œ ìŠ¤ì¼€ì¤„ë§ í•˜ì§€ ì•Šê³  ì„¤ì •ë§Œ ì €ì¥
                    if current_app.config.get('ENV') == 'development':
                        self._save_job_config(job_config)
                        current_app.logger.info(f"ğŸ’¾ ê°œë°œ í™˜ê²½: ì‘ì—… ì„¤ì • ì €ì¥ë¨ - {job_config.name}")
                    else:
                        # í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì‹¤ì œ ìŠ¤ì¼€ì¤„ë§
                        success = self.add_job(job_config)
                        if success:
                            current_app.logger.info(f"âœ… ê¸°ë³¸ ì‘ì—… ë“±ë¡ ì„±ê³µ: {job_config.name}")
                        else:
                            current_app.logger.error(f"âŒ ê¸°ë³¸ ì‘ì—… ë“±ë¡ ì‹¤íŒ¨: {job_config.name}")
                            
                except Exception as e:
                    current_app.logger.error(f"âŒ ê¸°ë³¸ ì‘ì—… ë“±ë¡ ì‹¤íŒ¨: {job_data.get('name', 'Unknown')} - {str(e)}")
                    continue
            
            current_app.logger.info("ğŸ”§ ê¸°ë³¸ ë°°ì¹˜ ì‘ì—… ë“±ë¡ ì™„ë£Œ")
            
        except Exception as e:
            current_app.logger.error(f"âŒ ê¸°ë³¸ ë°°ì¹˜ ì‘ì—… ë“±ë¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            import traceback
            current_app.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

    def _job_executed_listener(self, event):
        """ì‘ì—… ì‹¤í–‰ ì™„ë£Œ ë¦¬ìŠ¤ë„ˆ"""
        pass

    def _job_error_listener(self, event):
        """ì‘ì—… ì‹¤í–‰ ì˜¤ë¥˜ ë¦¬ìŠ¤ë„ˆ"""
        pass

    def _shutdown_scheduler(self, exception):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ í•¸ë“¤ëŸ¬"""
        pass

# ì „ì—­ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
batch_scheduler = BatchScheduler()

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    import time
    
    # í…ŒìŠ¤íŠ¸ìš© ìŠ¤ì¼€ì¤„ëŸ¬
    test_scheduler = BatchScheduler()
    test_scheduler.start()
    
    # í…ŒìŠ¤íŠ¸ ì‘ì—… ì¶”ê°€
    test_job = BatchJobConfig(
        job_id="test_job",
        name="í…ŒìŠ¤íŠ¸ ì‘ì—…",
        job_type="DAILY_COLLECTION",
        company_id=1,
        schedule_type="interval",
        interval_minutes=1  # 1ë¶„ë§ˆë‹¤ ì‹¤í–‰
    )
    
    test_scheduler.add_job(test_job)
    
    # 10ì´ˆ ëŒ€ê¸° í›„ ì¢…ë£Œ
    time.sleep(10)
    test_scheduler.stop() 